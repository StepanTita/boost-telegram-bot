{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7f387a9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d60f19e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: openai in /Users/stepanwork/opt/anaconda3/envs/mlpy38/lib/python3.8/site-packages (0.23.1)\n",
      "Requirement already satisfied: pandas-stubs>=1.1.0.11 in /Users/stepanwork/opt/anaconda3/envs/mlpy38/lib/python3.8/site-packages (from openai) (1.5.0.221012)\n",
      "Requirement already satisfied: typing-extensions in /Users/stepanwork/opt/anaconda3/envs/mlpy38/lib/python3.8/site-packages (from openai) (4.4.0)\n",
      "Requirement already satisfied: requests>=2.20 in /Users/stepanwork/opt/anaconda3/envs/mlpy38/lib/python3.8/site-packages (from openai) (2.27.1)\n",
      "Requirement already satisfied: pandas>=1.2.3 in /Users/stepanwork/opt/anaconda3/envs/mlpy38/lib/python3.8/site-packages (from openai) (1.3.4)\n",
      "Requirement already satisfied: numpy in /Users/stepanwork/opt/anaconda3/envs/mlpy38/lib/python3.8/site-packages (from openai) (1.21.4)\n",
      "Requirement already satisfied: tqdm in /Users/stepanwork/opt/anaconda3/envs/mlpy38/lib/python3.8/site-packages (from openai) (4.64.1)\n",
      "Requirement already satisfied: openpyxl>=3.0.7 in /Users/stepanwork/opt/anaconda3/envs/mlpy38/lib/python3.8/site-packages (from openai) (3.0.10)\n",
      "Requirement already satisfied: et-xmlfile in /Users/stepanwork/opt/anaconda3/envs/mlpy38/lib/python3.8/site-packages (from openpyxl>=3.0.7->openai) (1.1.0)\n",
      "Requirement already satisfied: pytz>=2017.3 in /Users/stepanwork/opt/anaconda3/envs/mlpy38/lib/python3.8/site-packages (from pandas>=1.2.3->openai) (2021.3)\n",
      "Requirement already satisfied: python-dateutil>=2.7.3 in /Users/stepanwork/opt/anaconda3/envs/mlpy38/lib/python3.8/site-packages (from pandas>=1.2.3->openai) (2.8.2)\n",
      "Requirement already satisfied: types-pytz>=2022.1.1 in /Users/stepanwork/opt/anaconda3/envs/mlpy38/lib/python3.8/site-packages (from pandas-stubs>=1.1.0.11->openai) (2022.4.0.0)\n",
      "Requirement already satisfied: six>=1.5 in /Users/stepanwork/opt/anaconda3/envs/mlpy38/lib/python3.8/site-packages (from python-dateutil>=2.7.3->pandas>=1.2.3->openai) (1.16.0)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in /Users/stepanwork/opt/anaconda3/envs/mlpy38/lib/python3.8/site-packages (from requests>=2.20->openai) (2.0.12)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/stepanwork/opt/anaconda3/envs/mlpy38/lib/python3.8/site-packages (from requests>=2.20->openai) (3.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/stepanwork/opt/anaconda3/envs/mlpy38/lib/python3.8/site-packages (from requests>=2.20->openai) (2021.10.8)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /Users/stepanwork/opt/anaconda3/envs/mlpy38/lib/python3.8/site-packages (from requests>=2.20->openai) (1.26.9)\n"
     ]
    }
   ],
   "source": [
    "!pip install --upgrade openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c5a1fdf2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Analyzing...\n",
      "\n",
      "- Your file contains 8353 prompt-completion pairs\n",
      "- All prompts end with suffix `\\n\\n###\\n\\n`\n",
      "- All completions end with suffix ` END`\n",
      "- The completion should start with a whitespace character (` `). This tends to produce better results due to the tokenization we use. See https://beta.openai.com/docs/guides/fine-tuning/preparing-your-dataset for more details\n",
      "\n",
      "Based on the analysis we will perform the following actions:\n",
      "- [Recommended] Add a whitespace character to the beginning of the completion [Y/n]: Y\n",
      "\n",
      "\n",
      "Your data will be written to a new JSONL file. Proceed [Y/n]: Y\n",
      "\n",
      "Wrote modified file to `./output/punctuation_stopwords_prepared.jsonl`\n",
      "Feel free to take a look!\n",
      "\n",
      "Now use that file when fine-tuning:\n",
      "> openai api fine_tunes.create -t \"./output/punctuation_stopwords_prepared.jsonl\"\n",
      "\n",
      "After you’ve fine-tuned a model, remember that your prompt has to end with the indicator string `\\n\\n###\\n\\n` for the model to start generating completions, rather than continuing with the prompt. Make sure to include `stop=[\" END\"]` so that the generated texts ends at the expected place.\n",
      "Once your model starts training, it'll approximately take 1.95 hours to train a `curie` model, and less for `ada` and `babbage`. Queue will approximately take half an hour per job ahead of you.\n"
     ]
    }
   ],
   "source": [
    "!openai tools fine_tunes.prepare_data -f ./output/punctuation_stopwords.jsonl -q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a6550b5d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Analyzing...\n",
      "\n",
      "- Your file contains 1872 prompt-completion pairs\n",
      "- All prompts end with suffix `\\n\\n###\\n\\n`\n",
      "- All completions end with suffix ` END`\n",
      "- The completion should start with a whitespace character (` `). This tends to produce better results due to the tokenization we use. See https://beta.openai.com/docs/guides/fine-tuning/preparing-your-dataset for more details\n",
      "\n",
      "Based on the analysis we will perform the following actions:\n",
      "- [Recommended] Add a whitespace character to the beginning of the completion [Y/n]: Y\n",
      "\n",
      "\n",
      "Your data will be written to a new JSONL file. Proceed [Y/n]: Y\n",
      "\n",
      "Wrote modified file to `./output/named_entity_extraction_3_prepared.jsonl`\n",
      "Feel free to take a look!\n",
      "\n",
      "Now use that file when fine-tuning:\n",
      "> openai api fine_tunes.create -t \"./output/named_entity_extraction_3_prepared.jsonl\"\n",
      "\n",
      "After you’ve fine-tuned a model, remember that your prompt has to end with the indicator string `\\n\\n###\\n\\n` for the model to start generating completions, rather than continuing with the prompt. Make sure to include `stop=[\" END\"]` so that the generated texts ends at the expected place.\n",
      "Once your model starts training, it'll approximately take 28.15 minutes to train a `curie` model, and less for `ada` and `babbage`. Queue will approximately take half an hour per job ahead of you.\n"
     ]
    }
   ],
   "source": [
    "!openai tools fine_tunes.prepare_data -f ./output/named_entity_extraction_3.jsonl -q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "824d414d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Analyzing...\n",
      "\n",
      "- Your file contains 8353 prompt-completion pairs\n",
      "- All prompts end with suffix `\\n\\n###\\n\\n`\n",
      "- All completions end with suffix ` END`\n",
      "- The completion should start with a whitespace character (` `). This tends to produce better results due to the tokenization we use. See https://beta.openai.com/docs/guides/fine-tuning/preparing-your-dataset for more details\n",
      "\n",
      "Based on the analysis we will perform the following actions:\n",
      "- [Recommended] Add a whitespace character to the beginning of the completion [Y/n]: Y\n",
      "\n",
      "\n",
      "Your data will be written to a new JSONL file. Proceed [Y/n]: Y\n",
      "\n",
      "Wrote modified file to `./output/punctuation_stopwords_lemmatization_prepared.jsonl`\n",
      "Feel free to take a look!\n",
      "\n",
      "Now use that file when fine-tuning:\n",
      "> openai api fine_tunes.create -t \"./output/punctuation_stopwords_lemmatization_prepared.jsonl\"\n",
      "\n",
      "After you’ve fine-tuned a model, remember that your prompt has to end with the indicator string `\\n\\n###\\n\\n` for the model to start generating completions, rather than continuing with the prompt. Make sure to include `stop=[\" END\"]` so that the generated texts ends at the expected place.\n",
      "Once your model starts training, it'll approximately take 1.95 hours to train a `curie` model, and less for `ada` and `babbage`. Queue will approximately take half an hour per job ahead of you.\n"
     ]
    }
   ],
   "source": [
    "!openai tools fine_tunes.prepare_data -f ./output/punctuation_stopwords_lemmatization.jsonl -q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a07374e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: OPENAI_API_KEY=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\n"
     ]
    }
   ],
   "source": [
    "%env OPENAI_API_KEY=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"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "099fd32b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TMPDIR=/var/folders/l4/kkbfk_xs52n01x_2cs6bv8g40000gp/T/\r\n",
      "__CFBundleIdentifier=com.apple.Terminal\r\n",
      "XPC_FLAGS=0x0\r\n",
      "TERM=xterm-color\r\n",
      "SSH_AUTH_SOCK=/private/tmp/com.apple.launchd.dOVAf3QZgr/Listeners\r\n",
      "XPC_SERVICE_NAME=0\r\n",
      "TERM_PROGRAM=Apple_Terminal\r\n",
      "TERM_PROGRAM_VERSION=440\r\n",
      "TERM_SESSION_ID=DFECF881-895E-4049-B139-33B10436E45F\r\n",
      "SHELL=/bin/zsh\r\n",
      "HOME=/Users/stepanwork\r\n",
      "LOGNAME=stepanwork\r\n",
      "USER=stepanwork\r\n",
      "PATH=/Users/stepanwork/opt/anaconda3/envs/mlpy38/bin:/Users/stepanwork/opt/anaconda3/condabin:/opt/homebrew/bin:/opt/homebrew/sbin:/usr/local/bin:/usr/bin:/bin:/usr/sbin:/sbin:/usr/local/go/bin:/usr/local/munki\r\n",
      "SHLVL=1\r\n",
      "PWD=/Users/stepanwork/Sandbox/Scripts/gpt-3-fine-tune\r\n",
      "OLDPWD=/Users/stepanwork/Sandbox/Scripts/gpt-3-fine-tune\r\n",
      "HOMEBREW_PREFIX=/opt/homebrew\r\n",
      "HOMEBREW_CELLAR=/opt/homebrew/Cellar\r\n",
      "HOMEBREW_REPOSITORY=/opt/homebrew\r\n",
      "MANPATH=/opt/homebrew/share/man::\r\n",
      "INFOPATH=/opt/homebrew/share/info:\r\n",
      "TEST_TMPDIR=/Volumes/SP-B75-Pro/Bazel/tmp\r\n",
      "CONDA_EXE=/Users/stepanwork/opt/anaconda3/bin/conda\r\n",
      "_CE_M=\r\n",
      "_CE_CONDA=\r\n",
      "CONDA_PYTHON_EXE=/Users/stepanwork/opt/anaconda3/bin/python\r\n",
      "CONDA_SHLVL=1\r\n",
      "CONDA_PREFIX=/Users/stepanwork/opt/anaconda3/envs/mlpy38\r\n",
      "CONDA_DEFAULT_ENV=mlpy38\r\n",
      "CONDA_PROMPT_MODIFIER=(mlpy38) \r\n",
      "LC_CTYPE=UTF-8\r\n",
      "PYDEVD_USE_FRAME_EVAL=NO\r\n",
      "JPY_PARENT_PID=2255\r\n",
      "__CF_USER_TEXT_ENCODING=0x1F6:0x0:0x0\r\n",
      "CLICOLOR=1\r\n",
      "PAGER=cat\r\n",
      "GIT_PAGER=cat\r\n",
      "MPLBACKEND=module://matplotlib_inline.backend_inline\r\n",
      "OPENAI_API_KEY=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\r\n",
      "_=/usr/bin/printenv\r\n"
     ]
    }
   ],
   "source": [
    "!printenv"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38e56b3a",
   "metadata": {},
   "source": [
    "# Fine-tuning NEE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8bc61b82",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Upload progress: 100%|███████████████████████| 361k/361k [00:00<00:00, 144Mit/s]\n",
      "Uploaded file from ./output/prepared/named_entity_extraction_3_prepared.jsonl: file-eGBXLQxh1tkHYLI9TZBVkc8G\n",
      "Created fine-tune: ft-8s8UatehCjaNod1zmO3UvUv6\n",
      "Streaming events until fine-tuning is complete...\n",
      "\n",
      "(Ctrl-C will interrupt the stream, but not cancel the fine-tune)\n",
      "[2022-10-17 21:04:42] Created fine-tune: ft-8s8UatehCjaNod1zmO3UvUv6\n",
      "[2022-10-17 21:04:54] Fine-tune costs $0.44\n",
      "[2022-10-17 21:04:54] Fine-tune enqueued. Queue number: 0\n",
      "[2022-10-17 21:04:55] Fine-tune started\n",
      "[2022-10-17 21:14:17] Completed epoch 1/2\n",
      "\n",
      "Stream interrupted (client disconnected).\n",
      "To resume the stream, run:\n",
      "\n",
      "  openai api fine_tunes.follow -i ft-8s8UatehCjaNod1zmO3UvUv6\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!openai api fine_tunes.create -t \"./output/prepared/named_entity_extraction_3_prepared.jsonl\" --n_epochs 2 --model 'curie' --learning_rate_multiplier 0.02"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8ed92e85",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2022-10-17 21:04:42] Created fine-tune: ft-8s8UatehCjaNod1zmO3UvUv6\n",
      "[2022-10-17 21:04:54] Fine-tune costs $0.44\n",
      "[2022-10-17 21:04:54] Fine-tune enqueued. Queue number: 0\n",
      "[2022-10-17 21:04:55] Fine-tune started\n",
      "[2022-10-17 21:14:17] Completed epoch 1/2\n",
      "[2022-10-17 21:22:44] Completed epoch 2/2\n",
      "[2022-10-17 21:23:21] Uploaded model: curie:ft-boost-2022-10-18-01-23-20\n",
      "[2022-10-17 21:23:22] Uploaded result file: file-R57TMKPWyotf9aN6YUD0Ftrc\n",
      "[2022-10-17 21:23:22] Fine-tune succeeded\n",
      "\n",
      "Job complete! Status: succeeded 🎉\n",
      "Try out your fine-tuned model:\n",
      "\n",
      "openai api completions.create -m curie:ft-boost-2022-10-18-01-23-20 -p <YOUR_PROMPT>\n"
     ]
    }
   ],
   "source": [
    "! openai api fine_tunes.follow -i ft-8s8UatehCjaNod1zmO3UvUv6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b79e8b66",
   "metadata": {},
   "outputs": [],
   "source": [
    "openai.api_key = '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'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "885292c1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' The US has imposed tariffs on steel and aluminium imports from the EU, Canada and Mexico.'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ft_model_name = 'curie:ft-boost-2022-10-18-01-23-20'\n",
    "res = openai.Completion.create(model=ft_model_name, prompt=\"Hunger,Europe,US\" + '\\n\\n###\\n\\n', max_tokens=256, temperature=0, stop=[\" END\"])\n",
    "res['choices'][0]['text']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7db78aa9",
   "metadata": {},
   "source": [
    "# Fine-tuning PS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "835f3013",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Upload progress: 100%|█████████████████████| 1.69M/1.69M [00:00<00:00, 674Mit/s]\n",
      "Uploaded file from ./output/prepared/punctuation_stopwords_prepared.jsonl: file-1DfAjvHwJgN6qstNNGHS2yih\n",
      "Created fine-tune: ft-yVLcGSaVrzbsTB6NgJAXlcy6\n",
      "Streaming events until fine-tuning is complete...\n",
      "\n",
      "(Ctrl-C will interrupt the stream, but not cancel the fine-tune)\n",
      "[2022-10-17 21:32:29] Created fine-tune: ft-yVLcGSaVrzbsTB6NgJAXlcy6\n",
      "[2022-10-17 21:32:44] Fine-tune costs $2.33\n",
      "[2022-10-17 21:32:44] Fine-tune enqueued. Queue number: 0\n",
      "[2022-10-17 21:32:46] Fine-tune started\n",
      "[2022-10-17 21:38:52] Completed epoch 1/2\n",
      "[2022-10-17 21:44:00] Completed epoch 2/2\n",
      "[2022-10-17 21:44:37] Uploaded model: curie:ft-boost-2022-10-18-01-44-36\n",
      "[2022-10-17 21:44:37] Uploaded result file: file-M4LvL796YLQt9FVf0f8r1c0c\n",
      "[2022-10-17 21:44:37] Fine-tune succeeded\n",
      "\n",
      "Job complete! Status: succeeded 🎉\n",
      "Try out your fine-tuned model:\n",
      "\n",
      "openai api completions.create -m curie:ft-boost-2022-10-18-01-44-36 -p <YOUR_PROMPT>\n"
     ]
    }
   ],
   "source": [
    "!openai api fine_tunes.create -t \"./output/prepared/punctuation_stopwords_prepared.jsonl\" --n_epochs 2 --model 'curie' --learning_rate_multiplier 0.02"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "3963a1d2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' The Queen\\'s death was announced by the Duke of Edinburgh, who said he was \"deeply saddened\".'"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ft_model_name = 'curie:ft-boost-2022-10-18-01-44-36'\n",
    "res = openai.Completion.create(model=ft_model_name, prompt=\"Queen,Death,Elizabeth\" + '\\n\\n###\\n\\n', max_tokens=256, temperature=0, stop=[\" END\"])\n",
    "res['choices'][0]['text']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1750997f",
   "metadata": {},
   "source": [
    "# Fine-tuning PSL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "63daebb1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Upload progress: 100%|█████████████████████| 1.68M/1.68M [00:00<00:00, 680Mit/s]\n",
      "Uploaded file from ./output/prepared/punctuation_stopwords_lemmatization_prepared.jsonl: file-kd77SKPf2iOTjonm0UQ7gySd\n",
      "Created fine-tune: ft-PWaLR9FX5Cxhbbh2JU4yjxy4\n",
      "Streaming events until fine-tuning is complete...\n",
      "\n",
      "(Ctrl-C will interrupt the stream, but not cancel the fine-tune)\n",
      "[2022-10-17 22:01:23] Created fine-tune: ft-PWaLR9FX5Cxhbbh2JU4yjxy4\n",
      "[2022-10-17 22:01:29] Fine-tune costs $2.30\n",
      "[2022-10-17 22:01:30] Fine-tune enqueued. Queue number: 0\n",
      "[2022-10-17 22:01:31] Fine-tune started\n",
      "[2022-10-17 22:07:49] Completed epoch 1/2\n",
      "[2022-10-17 22:13:06] Completed epoch 2/2\n",
      "[2022-10-17 22:13:27] Uploaded model: curie:ft-boost-2022-10-18-02-13-27\n",
      "[2022-10-17 22:13:28] Uploaded result file: file-3y3Cip8HWjCTWoI0mHCwP8Sl\n",
      "[2022-10-17 22:13:28] Fine-tune succeeded\n",
      "\n",
      "Job complete! Status: succeeded 🎉\n",
      "Try out your fine-tuned model:\n",
      "\n",
      "openai api completions.create -m curie:ft-boost-2022-10-18-02-13-27 -p <YOUR_PROMPT>\n"
     ]
    }
   ],
   "source": [
    "!openai api fine_tunes.create -t \"./output/prepared/punctuation_stopwords_lemmatization_prepared.jsonl\" --n_epochs 2 --model 'curie' --learning_rate_multiplier 0.02"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "c57b98d6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' The Ukrainian president says he will not allow Russia to \"destroy\" his country.'"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ft_model_name = 'curie:ft-boost-2022-10-18-02-13-27'\n",
    "res = openai.Completion.create(model=ft_model_name, prompt=\"Kiev,Ukraine,Zelensky\" + '\\n\\n###\\n\\n', max_tokens=256, temperature=0, stop=[\" END\"])\n",
    "res['choices'][0]['text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd6304a2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
